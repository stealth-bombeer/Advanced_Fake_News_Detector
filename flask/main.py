from helpers import fact_check, one_word, get_text, category_identifier, l_by_r, type_of_views, type_of_propaganda, news_type, hatespeech, clickbait, sentiment_analysis, extract_keywords, transcript_generation
from newspaper import Article
import openai
import nltk
from flask import Flask, request, jsonify
from flask_restful import Api, Resource, reqparse, marshal_with, fields
from flask_cors import CORS, cross_origin
import random
import re
import json
import pandas as pd
import PIL
import urllib.request
from PIL import Image
import pytesseract
from transformers import pipeline
import os
from os import listdir
from transformers import pipeline
zero_shot_classfier = pipeline("zero-shot-classification")

sales_img_captioning = pipeline(
    "image-to-text", model="Salesforce/blip-image-captioning-large")


app = Flask(__name__)
app.config['CORS_HEADERS'] = 'application/json'
app.app_context().push()
CORS(app)
api = Api(app)

# cors = CORS(resources={
#     r'/*': {
#         'origins': [
#             'http://localhost:3000',
#             '*'
#         ]
#     }
# })

cors = CORS(app, resources={
    r"/imagegenerator": {"origins": "*"}, r"/classify": {"origins": "*"}, r"/fact_check": {"origins": "*"}
})

# cors.init_app(app)

# -*- coding: utf-8 -*-
"""fake_news_gpt3_final.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1DGtAHo9Koxt2a48RMJMLPKlBrMfOYywF
"""

# imports
# get summary  of news
#

# installations
# !pip install nltk
# !pip install newspaper3k
# !pip install openai

nltk.download('punkt')

# @cross_origin(supports_credentials=True)
# ********************************* Authenticating a User Query ***********************************
# ************************************************************************************************

    """
    Input: HTTP POST request with data.
    Output: JSON response containing the result of fact-checking.
    Description: Receives a POST request, performs fact-checking using the fact_check() function, and returns the result as a JSON response.
    """

@app.route('/factcheck', methods=['POST'])
def verifier():

    print("Inside the verifier at the backend")
    data = request.data
    print("The request body is", data)
    result = fact_check(data)
    return jsonify({"result": result})

"""
Input: Text to be classified.
Output: Classification label ('misinformation or fake news' or 'factual news').
Description: Uses a zero-shot classification pipeline to classify the input text into categories related to misinformation or factual news.
"""
def news_type(text):

    final_classification = zero_shot_classfier(
        text, candidate_labels=["misinformation or fake news", "factual news"])
    return final_classification['labels'][0]


@app.route('/')

def homeRoute():
    return "Hello from Flask"


@app.route('/classify', methods=['POST'])
"""
Input: HTTP POST request with data.
Output: JSON response containing the classification result.
Description: Receives a POST request, extracts a single word from the input using the one_word() function, and returns the result as a JSON response.
"""
def classifier():
    print("Inside the classifier")
    query = request.data.decode()
    print(query)
    result = one_word(query)
    print(result)
    return jsonify({"result": result})


folder_dir = "C:/Users/Adwait/OneDrive/Desktop/builds/kavach/horizon-tailwind-react/flask/images"

"""
Input: Directory path.
Output: None.
Description: Deletes all files within the specified directory.
"""
def delete_files_in_directory(directory_path):
    try:
        files = os.listdir(directory_path)
        for file in files:
            file_path = os.path.join(directory_path, file)
            if os.path.isfile(file_path):
                os.remove(file_path)
        print("All files deleted successfully.")
    except OSError:
        print("Error occurred while deleting files.")
"""
Input: Image file name.
Output: Text extracted from the image using OCR.
Description: Uses Tesseract OCR to extract text from an image file.
"""

def images_to_ocr(image_filename):
    full_image_path = os.path.join(folder_dir, image_filename)
    img = PIL.Image.open(full_image_path)
    text = pytesseract.image_to_string(img.convert('L'), lang='eng')
    return text

"""
Input: Image file(s).
Output: Generated captions for the image(s).
Description: Uses a model (Salesforce/blip-image-captioning-large) to generate captions for image(s)
"""

def image_caption_generation(images):
    print("Inside icg")
    result = sales_img_captioning(images)[0]['generated_text']
    print("After icg")
    print(result)
    return result

"""
Input: Image file name.
Output: Text representation of the image content.
Description: Generates a textual representation of an image by either using OCR or generating a caption for the image.
"""
def text_representation_of_images(image):
    result = ""
    ocr_text = images_to_ocr(image)
    combined_text = ''
    if len(ocr_text) <= 4:
        full_image_path = os.path.join(folder_dir, image)
        caption = image_caption_generation(full_image_path)
        combined_text = caption
    else:
        combined_text = ocr_text
    result += combined_text + "\n"
    delete_files_in_directory(folder_dir)
    return result


# @app.route('/imagegenerator', methods=['POST'])
# def imageGenerator():
#     print("Inside the image generaotr at the backend")
#     data = request.data
#     print("The request body is", data)
#     print(type(data))
#     finalURL = data.decode()
#     num = random.randrange(10000000)
#     urllib.request.urlretrieve(finalURL, f'/images/{num}.png')
#     return jsonify({"result": "name"})

"""
Input: Text query.
Output: List of various classifications based on the query.
Description: Performs different types of classification (e.g., category, propaganda, hate speech) on the input text and returns the results as a list.
"""

def classify_generated_caption(query):
    category = category_identifier(query)
    lbyr = l_by_r(query)
    viewType = type_of_views(query)
    newsType = news_type(query)
    propogandaType = type_of_propaganda(query)
    speechType = hatespeech(query)
    clickbaitType = clickbait(query)
    sentiment = sentiment_analysis(query)
    impKeywords = extract_keywords(query)
    data = [category, lbyr, viewType, newsType, propogandaType,
            speechType, clickbaitType, sentiment, impKeywords]

    return data


@ app.route('/imagegenerator', methods=['POST', 'OPTIONS'])
"""
Input: HTTP POST request with data containing an image URL.
Output: JSON response with classifications based on the generated text from the image.
Description: Receives an image URL, downloads the image, processes it to generate text representation, performs multiple classifications based on the generated text, and returns the results as a JSON response
"""
def imageGenerator():
    if request.method == 'OPTIONS':
        # Handle preflight request
        response = app.make_default_options_response()
    else:
        # Handle actual POST request
        data = request.data
        finalURL = data.decode()
        print(finalURL)
        num = random.randrange(10000000)
        urllib.request.urlretrieve(
            finalURL, f'C:/Users/Adwait/OneDrive/Desktop/builds/kavach/horizon-tailwind-react/flask/images/{num}.png')
        # images_list = []

        # for images in os.listdir(folder_dir):
        #     if (images.endswith(".png")):
        #         images_list.append(images)

    # response = jsonify({"result": text_representation_of_images(images_list)})
    result = text_representation_of_images(os.listdir(folder_dir)[0])
    print("About to print the result")
    print(result)
    ans = classify_generated_caption(result)
    return jsonify(ans)


@app.route('/category_classifier', methods=['POST'])
"""
Input: HTTP POST request with data.
Output: JSON response containing various classifications based on the input text.
Description: Receives a text query, performs multiple classifications (e.g., category, sentiment, hate speech detection) on the text, and returns the results as a JSON response
"""
def text_classification():
    print("Inside the category classifier")
    query = request.data.decode()
    print(query)
    category = category_identifier(query)
    lbyr = l_by_r(query)
    viewType = type_of_views(query)
    newsType = news_type(query)
    propogandaType = type_of_propaganda(query)
    speechType = hatespeech(query)
    clickbaitType = clickbait(query)
    sentiment = sentiment_analysis(query)
    impKeywords = extract_keywords(query)
    data = [category, lbyr, viewType, newsType, propogandaType,
            speechType, clickbaitType, sentiment, impKeywords]

    return jsonify(data)


@app.route('/short_classifier', methods=['POST'])
"""
Input: HTTP POST request with data.
Output: JSON response containing various classifications based on the generated transcript.
Description: Receives a short text query, generates a transcript, performs multiple classifications (similar to text_classification()), and returns the results as a JSON response.
"""
def short_classification():
    print("Inside the short classifier")
    query = request.data.decode()
    print(query)
    result = transcript_generation(query)
    print("The transcript has been generated")

    category = category_identifier(result)
    lbyr = l_by_r(result)
    viewType = type_of_views(result)
    newsType = news_type(result)
    propogandaType = type_of_propaganda(result)
    speechType = hatespeech(result)
    clickbaitType = clickbait(result)
    sentiment = sentiment_analysis(result)
    impKeywords = extract_keywords(result)
    data = [category, lbyr, viewType, newsType, propogandaType,
            speechType, clickbaitType, sentiment, impKeywords]

    print(data)
    return jsonify(data)


if __name__ == "__main__":
    app.run(debug=True)
